#!/usr/bin/env python3
"""
è½»é‡ docgenï¼šæ±‡æ€»å…³é”®æ–‡æ¡£è·¯å¾„ä¸º index.json ä¸ module_index.json
æ–°å¢ï¼šsummary/keywords/deps/version/snapshot_hash
"""
import json
import pathlib
import re
import hashlib
from datetime import datetime
from collections import Counter

def sha256_file(path):
    """è®¡ç®—æ–‡ä»¶çš„ SHA256 å“ˆå¸Œ"""
    try:
        content = path.read_bytes()
        return hashlib.sha256(content).hexdigest()[:16]  # å–å‰16å­—ç¬¦
    except:
        return "error"

def extract_summary(path, max_len=240):
    """æå–æ–‡æ¡£æ‘˜è¦ï¼ˆé¦– max_len å­—ç¬¦ï¼Œè·³è¿‡ç©ºè¡Œå’Œæ ‡é¢˜ï¼‰"""
    try:
        content = path.read_text(encoding='utf-8')
        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.strip().startswith('#')]
        summary = ' '.join(lines)[:max_len]
        return summary if summary else "(empty)"
    except:
        return "(error)"

def extract_keywords(path, top_n=5):
    """æå–å…³é”®è¯ï¼ˆç®€æ˜“ TF ç»Ÿè®¡ï¼‰"""
    try:
        content = path.read_text(encoding='utf-8').lower()
        # ç®€å•åˆ†è¯ï¼ˆç§»é™¤æ ‡ç‚¹ï¼‰
        words = re.findall(r'\b[a-z]{3,}\b', content)
        # åœç”¨è¯
        stopwords = {'the', 'and', 'for', 'this', 'that', 'with', 'from', 'are', 'was', 'not'}
        words = [w for w in words if w not in stopwords]
        counter = Counter(words)
        return [w for w, _ in counter.most_common(top_n)]
    except:
        return []

def extract_deps(path):
    """æå–æ–‡æ¡£ä¾èµ–ï¼ˆæ–‡ä»¶å¼•ç”¨å’Œå¥‘çº¦å¼•ç”¨ï¼‰"""
    deps = []
    try:
        content = path.read_text(encoding='utf-8')
        # æŸ¥æ‰¾æ–‡ä»¶å¼•ç”¨æ¨¡å¼ï¼š`/path/to/file` æˆ– "path/to/file"
        file_refs = re.findall(r'[`"]([a-zA-Z0-9_/.]+\.(md|yaml|json|py|sh))[`"]', content)
        deps.extend([ref[0] for ref in file_refs])
        
        # æŸ¥æ‰¾å¥‘çº¦å¼•ç”¨
        contract_refs = re.findall(r'(tools/[a-zA-Z0-9_/]+/contract\.json)', content)
        deps.extend(contract_refs)
    except:
        pass
    return list(set(deps))  # å»é‡

def scan_docs():
    """æ‰«ææ–‡æ¡£å¹¶ç”Ÿæˆç´¢å¼•"""
    root = pathlib.Path('.')
    index = {"docs": [], "generated_at": datetime.now().isoformat()}
    
    # æ‰«æå…³é”®ç›®å½•
    target_dirs = ['docs', 'modules', 'flows', 'tools', '.aicontext']
    
    for p in root.rglob('*'):
        if p.is_file() and p.suffix in {'.md', '.yaml', '.json'}:
            # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡ç›®å½•ä¸­
            if any(str(p).startswith(s) for s in target_dirs):
                doc_info = {
                    "path": str(p).replace('\\', '/'),
                    "hash": sha256_file(p),
                    "summary": extract_summary(p) if p.suffix == '.md' else None,
                    "keywords": extract_keywords(p) if p.suffix == '.md' else None,
                    "deps": extract_deps(p) if p.suffix == '.md' else None
                }
                index["docs"].append(doc_info)
    
    return index

def build_module_index():
    """æ„å»ºæ¨¡å—ç´¢å¼•"""
    root = pathlib.Path('.')
    mod = {}
    
    modules_dir = root / 'modules'
    if modules_dir.exists():
        for m in modules_dir.glob('*'):
            if m.is_dir():
                mod[m.name] = {
                    "readme": str(m/'README.md').replace('\\', '/'),
                    "plan": str(m/'plan.md').replace('\\', '/'),
                    "contract": str(m/'CONTRACT.md').replace('\\', '/'),
                    "test_plan": str(m/'TEST_PLAN.md').replace('\\', '/'),
                    "tests": f"tests/{m.name}/"
                }
    
    return {"modules": mod, "generated_at": datetime.now().isoformat()}

def compute_snapshot_hash(index_data):
    """è®¡ç®—æ•´ä¸ªç´¢å¼•çš„å¿«ç…§å“ˆå¸Œ"""
    # æ’åºååºåˆ—åŒ–ï¼Œç¡®ä¿ç¨³å®šæ€§
    sorted_json = json.dumps(index_data, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(sorted_json.encode()).hexdigest()[:16]

def main():
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    pathlib.Path('.aicontext').mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡æ¡£ç´¢å¼•
    print("ğŸ“š æ‰«ææ–‡æ¡£...")
    index = scan_docs()
    
    # ç”Ÿæˆæ¨¡å—ç´¢å¼•
    print("ğŸ“¦ æ„å»ºæ¨¡å—ç´¢å¼•...")
    module_index = build_module_index()
    
    # è®¡ç®—å¿«ç…§å“ˆå¸Œ
    snapshot_hash = compute_snapshot_hash({"index": index, "modules": module_index})
    
    # ç”Ÿæˆ snapshot.json
    snapshot = {
        "snapshot_hash": snapshot_hash,
        "generated_at": datetime.now().isoformat(),
        "version": "1.0"
    }
    
    # å†™å…¥æ–‡ä»¶
    index_path = pathlib.Path('.aicontext/index.json')
    index_path.write_text(json.dumps(index, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"âœ“ ç”Ÿæˆ {index_path}")
    
    module_path = pathlib.Path('.aicontext/module_index.json')
    module_path.write_text(json.dumps(module_index, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"âœ“ ç”Ÿæˆ {module_path}")
    
    snapshot_path = pathlib.Path('.aicontext/snapshot.json')
    snapshot_path.write_text(json.dumps(snapshot, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"âœ“ ç”Ÿæˆ {snapshot_path} (hash: {snapshot_hash})")
    
    print("\nâœ… docgen å®Œæˆ")

if __name__ == '__main__':
    main()
