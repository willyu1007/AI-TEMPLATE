#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
issue_aggregator.py - Issue Aggregation and Root Cause Analysis

Provides intelligent issue clustering and root cause analysis:
- Cluster similar issues by pattern
- Identify root causes affecting multiple issues
- Generate batch fix proposals
- Calculate improvement potential

Created: 2025-11-09 (Phase 14.2+)
"""

import sys
import json
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from collections import defaultdict

# Windows UTF-8 support
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Import Issue model
from issue_model import Issue, IssueLevel, IssueCategory


@dataclass
class IssueCluster:
    """Cluster of similar issues"""
    name: str                    # Cluster name
    root_cause: str             # Root cause description
    affected_issues: List[Issue] = field(default_factory=list)
    impact_score: int = 0       # Total impact score
    fix_strategy: str = ""      # Proposed fix strategy


@dataclass
class RootCause:
    """Root cause analysis result"""
    id: str                     # Root cause ID (e.g., "RC-001")
    name: str                   # Short name
    description: str            # Detailed description
    affected_dimensions: List[str] = field(default_factory=list)
    affected_count: int = 0     # Number of affected issues
    fix_proposal: str = ""      # Fix proposal with commands
    expected_improvement: str = ""  # Expected score improvement
    estimated_time: str = ""    # Estimated fix time


class IssueAggregator:
    """
    Issue Aggregator for clustering and root cause analysis
    
    Features:
    - Cluster similar issues by pattern
    - Identify root causes
    - Generate batch fix proposals
    - Prioritize improvements
    """
    
    def __init__(self, issues: List[Issue]):
        """
        Initialize aggregator
        
        Args:
            issues: List of Issue objects
        """
        self.issues = issues
        self.clusters: List[IssueCluster] = []
        self.root_causes: List[RootCause] = []
    
    def cluster_similar_issues(self) -> List[IssueCluster]:
        """
        Cluster similar issues together
        
        Returns:
            List of IssueCluster objects
        """
        clusters = []
        
        # Cluster 1: Testing infrastructure issues
        test_issues = [
            i for i in self.issues 
            if any(keyword in i.message.lower() for keyword in ['test', 'coverage', 'pytest'])
        ]
        if test_issues:
            clusters.append(IssueCluster(
                name="æµ‹è¯•åŸºç¡€è®¾æ–½é—®é¢˜",
                root_cause="Testing infrastructure not configured or insufficient",
                affected_issues=test_issues,
                impact_score=sum(i.priority for i in test_issues),
                fix_strategy="Setup pytest infrastructure with coverage tools"
            ))
        
        # Cluster 2: Documentation issues
        doc_issues = [
            i for i in self.issues
            if i.category == IssueCategory.DOCUMENTATION or 
            any(keyword in i.message.lower() for keyword in ['document', 'doc', 'readme', 'missing'])
        ]
        if doc_issues:
            clusters.append(IssueCluster(
                name="æ–‡æ¡£å®Œæ•´æ€§é—®é¢˜",
                root_cause="Module documentation templates missing or incomplete",
                affected_issues=doc_issues,
                impact_score=sum(i.priority for i in doc_issues),
                fix_strategy="Generate missing documentation using templates"
            ))
        
        # Cluster 3: Code quality issues
        quality_issues = [
            i for i in self.issues
            if i.category == IssueCategory.CODE_QUALITY and
            any(keyword in i.message.lower() for keyword in ['linter', 'complexity', 'type'])
        ]
        if quality_issues:
            clusters.append(IssueCluster(
                name="ä»£ç è´¨é‡é—®é¢˜",
                root_cause="Code quality tools not configured or standards not met",
                affected_issues=quality_issues,
                impact_score=sum(i.priority for i in quality_issues),
                fix_strategy="Configure linters and refactor complex code"
            ))
        
        # Cluster 4: Security issues
        security_issues = [
            i for i in self.issues
            if i.category == IssueCategory.SECURITY or 'secret' in i.message.lower()
        ]
        if security_issues:
            clusters.append(IssueCluster(
                name="å®‰å…¨é—®é¢˜",
                root_cause="Secrets or credentials hardcoded in code",
                affected_issues=security_issues,
                impact_score=sum(i.priority for i in security_issues),
                fix_strategy="Move all secrets to environment variables"
            ))
        
        # Cluster 5: Architecture issues
        arch_issues = [
            i for i in self.issues
            if i.category == IssueCategory.ARCHITECTURE
        ]
        if arch_issues:
            clusters.append(IssueCluster(
                name="æ¶æ„è®¾è®¡é—®é¢˜",
                root_cause="Module dependencies or architecture not optimal",
                affected_issues=arch_issues,
                impact_score=sum(i.priority for i in arch_issues),
                fix_strategy="Refactor module relationships"
            ))
        
        self.clusters = sorted(clusters, key=lambda x: x.impact_score, reverse=True)
        return self.clusters
    
    def analyze_root_causes(self) -> List[RootCause]:
        """
        Analyze root causes of issues
        
        Returns:
            List of RootCause objects
        """
        root_causes = []
        
        # Root Cause 1: Testing infrastructure missing
        test_related = [
            i for i in self.issues
            if any(kw in i.message.lower() for kw in ['test', 'coverage', 'pytest'])
        ]
        if len(test_related) >= 3:  # Significant impact
            root_causes.append(RootCause(
                id="RC-001",
                name="æµ‹è¯•åŸºç¡€è®¾æ–½ç¼ºå¤±",
                description="No pytest or coverage tools configured, leading to zero test coverage",
                affected_dimensions=['code_quality', 'operations'],
                affected_count=len(test_related),
                fix_proposal="""
**ä¸€é”®ä¿®å¤æ–¹æ¡ˆ**:
```bash
# 1. å®‰è£…æµ‹è¯•å·¥å…·
pip install pytest pytest-cov pytest-mock

# 2. åˆ›å»ºé…ç½®æ–‡ä»¶
cat > pytest.ini << EOF
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = --cov=modules --cov=scripts --cov-report=term-missing
EOF

# 3. è¿è¡Œé¦–æ¬¡æµ‹è¯•
make test_coverage
```

å°†è§£å†³ {count} ä¸ªé—®é¢˜ï¼Œæ¶‰åŠä»¥ä¸‹æ–‡ä»¶:
- {files}
                """.format(
                    count=len(test_related),
                    files="\n- ".join(set(i.file for i in test_related if i.file))[:500]
                ),
                expected_improvement="+15-20åˆ†",
                estimated_time="1-2å°æ—¶"
            ))
        
        # Root Cause 2: Module documentation incomplete
        doc_issues = [
            i for i in self.issues
            if i.category == IssueCategory.DOCUMENTATION and 'missing' in i.message.lower()
        ]
        if len(doc_issues) >= 2:
            affected_modules = set()
            for issue in doc_issues:
                if issue.file and 'modules/' in issue.file:
                    module = issue.file.split('modules/')[1].split('/')[0]
                    affected_modules.add(module)
            
            root_causes.append(RootCause(
                id="RC-002",
                name="æ¨¡å—æ–‡æ¡£æ¨¡æ¿ç¼ºå¤±",
                description=f"Modules missing standard documentation (affects {len(affected_modules)} module(s))",
                affected_dimensions=['documentation', 'ai_friendliness'],
                affected_count=len(doc_issues),
                fix_proposal=f"""
**æ‰¹é‡ä¿®å¤æ–¹æ¡ˆ**:
```bash
# ä¸ºæ¯ä¸ªæ¨¡å—ç”Ÿæˆç¼ºå¤±æ–‡æ¡£
{chr(10).join([f"make module_doc_gen MODULE={m}" for m in sorted(affected_modules)])}
```

å°†è‡ªåŠ¨åˆ›å»º:
- RUNBOOK.md (è¿ç»´æ‰‹å†Œ)
- BUGS.md (å·²çŸ¥é—®é¢˜)
- PROGRESS.md (è¿›åº¦è¿½è¸ª)
- TEST_PLAN.md (æµ‹è¯•è®¡åˆ’)
                """,
                expected_improvement="+5-8åˆ†",
                estimated_time="30åˆ†é’Ÿ-1å°æ—¶"
            ))
        
        # Root Cause 3: Linter/code quality tools not configured
        linter_issues = [
            i for i in self.issues
            if 'linter' in i.message.lower() or 'complexity' in i.message.lower()
        ]
        if len(linter_issues) >= 2:
            root_causes.append(RootCause(
                id="RC-003",
                name="ä»£ç è´¨é‡å·¥å…·æœªé…ç½®",
                description="Linters and complexity tools not properly configured",
                affected_dimensions=['code_quality'],
                affected_count=len(linter_issues),
                fix_proposal="""
**é…ç½®ä»£ç è´¨é‡å·¥å…·**:
```bash
# 1. å®‰è£…å·¥å…·
pip install pylint flake8 radon mypy

# 2. åˆ›å»ºé…ç½®
cat > .pylintrc << EOF
[MASTER]
max-line-length=120
EOF

# 3. è¿è¡Œæ£€æŸ¥
make python_scripts_lint
make complexity_check
```
                """,
                expected_improvement="+8-10åˆ†",
                estimated_time="1-1.5å°æ—¶"
            ))
        
        # Root Cause 4: Secrets not externalized
        secret_issues = [
            i for i in self.issues
            if 'secret' in i.message.lower() or 'password' in i.message.lower()
        ]
        if len(secret_issues) >= 1:
            root_causes.append(RootCause(
                id="RC-004",
                name="æ•æ„Ÿä¿¡æ¯ç¡¬ç¼–ç ",
                description="Secrets, passwords, or tokens hardcoded in configuration",
                affected_dimensions=['security', 'operations'],
                affected_count=len(secret_issues),
                fix_proposal="""
**è¿ç§»åˆ°ç¯å¢ƒå˜é‡**:
```bash
# 1. åˆ›å»º.env.exampleæ¨¡æ¿
cat > .env.example << EOF
DB_PASSWORD=your_password_here
AWS_SECRET_KEY=your_key_here
API_TOKEN=your_token_here
EOF

# 2. æ›´æ–°é…ç½®æ–‡ä»¶ä½¿ç”¨ç¯å¢ƒå˜é‡
# config/prod.yaml:
# password: ${DB_PASSWORD}

# 3. ç¡®ä¿.envåœ¨.gitignoreä¸­
echo ".env" >> .gitignore
```
                """,
                expected_improvement="+5-10åˆ†ï¼ˆé˜»æ–­é—®é¢˜ï¼‰",
                estimated_time="15-30åˆ†é’Ÿ"
            ))
        
        self.root_causes = sorted(root_causes, key=lambda x: x.affected_count, reverse=True)
        return self.root_causes
    
    def generate_aggregated_report(self) -> str:
        """
        Generate aggregated analysis report
        
        Returns:
            Markdown formatted aggregation report
        """
        clusters = self.cluster_similar_issues()
        root_causes = self.analyze_root_causes()
        
        md = "## ğŸ¯ é—®é¢˜èšåˆåˆ†æ\n\n"
        
        if not root_causes:
            md += "âœ… æœªæ£€æµ‹åˆ°éœ€è¦èšåˆåˆ†æçš„é—®é¢˜æ¨¡å¼\n\n"
            return md
        
        md += f"è¯†åˆ«åˆ° **{len(root_causes)}ä¸ªæ ¹æœ¬åŸå› **ï¼Œå½±å“ **{sum(rc.affected_count for rc in root_causes)}ä¸ªé—®é¢˜**\n\n"
        md += "---\n\n"
        
        for i, rc in enumerate(root_causes, 1):
            md += f"### æ ¹æœ¬åŸå› {i}: {rc.name}\n\n"
            md += f"**ID**: {rc.id}  \n"
            md += f"**å½±å“èŒƒå›´**: {rc.affected_count}ä¸ªé—®é¢˜ï¼Œæ¶‰åŠ {', '.join(rc.affected_dimensions)} ç»´åº¦  \n"
            md += f"**æ ¹æœ¬åŸå› **: {rc.description}  \n\n"
            
            md += rc.fix_proposal
            md += "\n\n"
            
            md += f"**é¢„æœŸæ•ˆæœ**: {rc.expected_improvement}  \n"
            md += f"**é¢„ä¼°æ—¶é—´**: {rc.estimated_time}  \n\n"
            md += "---\n\n"
        
        # Add cluster summary
        if clusters:
            md += "### é—®é¢˜èšç±»æ±‡æ€»\n\n"
            md += "| èšç±»åç§° | é—®é¢˜æ•° | å½±å“åˆ†æ•° | ä¿®å¤ç­–ç•¥ |\n"
            md += "|----------|--------|----------|----------|\n"
            for cluster in clusters:
                md += f"| {cluster.name} | {len(cluster.affected_issues)} | {cluster.impact_score} | {cluster.fix_strategy} |\n"
            md += "\n"
        
        return md
    
    def get_quick_wins(self, max_count: int = 5) -> List[Issue]:
        """
        Get quick win issues (high impact, low effort)
        
        Args:
            max_count: Maximum number of quick wins to return
            
        Returns:
            List of quick win issues
        """
        # Filter issues with high priority and short estimated time
        quick_wins = []
        
        time_keywords = ['minute', 'min', '15', '30']
        for issue in self.issues:
            if issue.priority >= 60 and issue.estimated_time:
                if any(kw in issue.estimated_time.lower() for kw in time_keywords):
                    quick_wins.append(issue)
        
        return sorted(quick_wins, key=lambda x: x.priority, reverse=True)[:max_count]
    
    def calculate_improvement_potential(self) -> Dict[str, float]:
        """
        Calculate potential score improvement by fixing issues
        
        Returns:
            Dict mapping urgency level to potential improvement
        """
        improvement = {
            'immediate': 0.0,
            'short_term': 0.0,
            'long_term': 0.0
        }
        
        for issue in self.issues:
            # Estimate score impact based on priority
            impact = issue.priority / 10
            
            if issue.is_high_priority():
                improvement['immediate'] += impact
            elif issue.level == IssueLevel.WARNING:
                improvement['short_term'] += impact
            else:
                improvement['long_term'] += impact
        
        return improvement
    
    def save_aggregated_report(self, output_path: str):
        """
        Save aggregated analysis report
        
        Args:
            output_path: Output file path
        """
        report = self.generate_aggregated_report()
        
        # Add quick wins section
        quick_wins = self.get_quick_wins()
        if quick_wins:
            report += "## ğŸš€ å¿«é€Ÿæ”¹è¿›ï¼ˆQuick Winsï¼‰\n\n"
            report += "ä»¥ä¸‹é—®é¢˜å¯å¿«é€Ÿä¿®å¤ï¼ˆé«˜å½±å“ã€ä½è€—æ—¶ï¼‰ï¼š\n\n"
            for i, issue in enumerate(quick_wins, 1):
                report += f"{i}. **[{issue.rule}]** {issue.message}\n"
                if issue.fix_command:
                    report += f"   - å‘½ä»¤: `{issue.fix_command}`\n"
                report += f"   - æ—¶é—´: {issue.estimated_time}\n"
                report += f"   - å½±å“: +{issue.priority/10:.0f}åˆ†\n\n"
        
        # Add improvement potential
        potential = self.calculate_improvement_potential()
        report += "## ğŸ“ˆ æ”¹è¿›æ½œåŠ›åˆ†æ\n\n"
        report += f"- **ç«‹å³ä¿®å¤** ({len([i for i in self.issues if i.is_high_priority()])}ä¸ª): çº¦ +{potential['immediate']:.0f}åˆ†\n"
        report += f"- **çŸ­æœŸæ”¹è¿›** ({len([i for i in self.issues if i.level == IssueLevel.WARNING])}ä¸ª): çº¦ +{potential['short_term']:.0f}åˆ†\n"
        report += f"- **é•¿æœŸä¼˜åŒ–** ({len([i for i in self.issues if not i.is_high_priority() and i.level != IssueLevel.WARNING])}ä¸ª): çº¦ +{potential['long_term']:.0f}åˆ†\n"
        report += f"- **æ€»æ½œåŠ›**: çº¦ +{sum(potential.values()):.0f}åˆ†\n\n"
        
        # Save report
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… Aggregated report saved: {output_path}")


# Example usage and testing
if __name__ == '__main__':
    from issue_model import create_issue
    
    print("=== Issue Aggregator Test ===\n")
    
    # Create sample issues
    test_issues = [
        create_issue(
            level="error",
            category="code_quality",
            rule="CQ-001",
            message="Test coverage too low: 45% (target: â‰¥90%)",
            file="modules/common/utils.py",
            suggestion="Add unit tests",
            fix_command="pytest tests/",
            estimated_time="2 hours",
            priority=85
        ),
        create_issue(
            level="error",
            category="code_quality",
            rule="CQ-002",
            message="Test coverage missing for module",
            file="modules/user/service.py",
            suggestion="Create test file",
            estimated_time="1 hour",
            priority=80
        ),
        create_issue(
            level="warning",
            category="documentation",
            rule="DOC-001",
            message="Module common missing RUNBOOK.md",
            file="modules/common/doc/",
            suggestion="Create RUNBOOK.md",
            fix_command="make module_doc_gen MODULE=common",
            estimated_time="30 minutes",
            priority=60
        ),
        create_issue(
            level="warning",
            category="documentation",
            rule="DOC-002",
            message="Module user missing TEST_PLAN.md",
            file="modules/user/doc/",
            suggestion="Create TEST_PLAN.md",
            estimated_time="20 minutes",
            priority=55
        ),
        create_issue(
            level="blocker",
            category="security",
            rule="BLOCKER-001",
            message="Potential secret detected in config",
            file="config/prod.yaml",
            line=45,
            suggestion="Move to environment variable",
            fix_command="export DB_PASSWORD=xxx",
            estimated_time="15 minutes",
            priority=100
        )
    ]
    
    # Create aggregator
    aggregator = IssueAggregator(test_issues)
    
    # Test clustering
    print("Clustering similar issues...")
    clusters = aggregator.cluster_similar_issues()
    print(f"Found {len(clusters)} clusters\n")
    
    for cluster in clusters:
        print(f"  - {cluster.name}: {len(cluster.affected_issues)} issues (impact: {cluster.impact_score})")
    
    # Test root cause analysis
    print("\nAnalyzing root causes...")
    root_causes = aggregator.analyze_root_causes()
    print(f"Found {len(root_causes)} root causes\n")
    
    for rc in root_causes:
        print(f"  - [{rc.id}] {rc.name}: {rc.affected_count} issues")
    
    # Test quick wins
    print("\nIdentifying quick wins...")
    quick_wins = aggregator.get_quick_wins()
    print(f"Found {len(quick_wins)} quick wins\n")
    
    # Calculate improvement potential
    print("Calculating improvement potential...")
    potential = aggregator.calculate_improvement_potential()
    print(f"  - Immediate: +{potential['immediate']:.0f} points")
    print(f"  - Short-term: +{potential['short_term']:.0f} points")
    print(f"  - Long-term: +{potential['long_term']:.0f} points")
    print(f"  - Total: +{sum(potential.values()):.0f} points")
    
    # Save report
    print("\nGenerating aggregated report...")
    aggregator.save_aggregated_report('temp/test-aggregated-report.md')
    
    print("\nâœ… Issue aggregator test completed successfully!")

