# å¯è§‚æµ‹æ€§é…ç½®

## ç›®æ ‡
æä¾›å¼€ç®±å³ç”¨çš„ç›‘æ§ã€æ—¥å¿—ã€è¿½è¸ªé…ç½®ï¼Œå¸®åŠ©é¡¹ç›®å¿«é€Ÿå»ºç«‹å¯è§‚æµ‹æ€§ä½“ç³»ã€‚

## é€‚ç”¨åœºæ™¯
- éœ€è¦ç›‘æ§åº”ç”¨æ€§èƒ½å’Œå¥åº·çŠ¶æ€
- éœ€è¦é›†ä¸­æ”¶é›†å’Œåˆ†ææ—¥å¿—
- éœ€è¦è¿½è¸ªåˆ†å¸ƒå¼è¯·æ±‚é“¾è·¯
- éœ€è¦å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶

## å‰ç½®æ¡ä»¶
- å·²ç¡®å®šç›‘æ§éœ€æ±‚
- å·²é€‰æ‹©ç›‘æ§å·¥å…·æ ˆï¼ˆPrometheus/Grafana/ELK/Jaegerç­‰ï¼‰

---

## ç›®å½•ç»“æ„

```
observability/
â”œâ”€â”€ README.md           # æœ¬æ–‡ä»¶
â”œâ”€â”€ logging/            # æ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ logstash.conf      # Logstash é…ç½®
â”‚   â”œâ”€â”€ fluentd.yaml       # Fluentd é…ç½®
â”‚   â””â”€â”€ python_logging.yaml # Python logging é…ç½®
â”œâ”€â”€ metrics/            # æŒ‡æ ‡é…ç½®
â”‚   â”œâ”€â”€ prometheus.yml     # Prometheus é…ç½®
â”‚   â””â”€â”€ grafana_dashboards/ # Grafana ä»ªè¡¨ç›˜
â”‚       â””â”€â”€ app_dashboard.json
â”œâ”€â”€ tracing/            # é“¾è·¯è¿½è¸ª
â”‚   â”œâ”€â”€ jaeger.yaml        # Jaeger é…ç½®
â”‚   â””â”€â”€ opentelemetry.yaml # OpenTelemetry é…ç½®
â””â”€â”€ alerts/             # å‘Šè­¦é…ç½®
    â”œâ”€â”€ prometheus_alerts.yml
    â””â”€â”€ alertmanager.yml
```

---

## å¿«é€Ÿå¼€å§‹

### 1. æ—¥å¿—æ”¶é›†ï¼ˆELK Stackï¼‰

#### ä½¿ç”¨ Logstash
```yaml
# observability/logging/logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] {
    mutate {
      add_field => { "service" => "%{[fields][service]}" }
    }
  }
  
  # è§£æ JSON æ—¥å¿—
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # è§£ææ—¶é—´æˆ³
  date {
    match => [ "timestamp", "ISO8601" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
}
```

#### ä½¿ç”¨ Fluentd
```yaml
# observability/logging/fluentd.yaml
<source>
  @type forward
  port 24224
</source>

<filter app.**>
  @type parser
  format json
  key_name message
  reserve_data true
</filter>

<match app.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name app-logs
  type_name _doc
  <buffer>
    flush_interval 10s
  </buffer>
</match>
```

#### Python logging é…ç½®
```yaml
# observability/logging/python_logging.yaml
version: 1
formatters:
  json:
    format: '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "message": "%(message)s", "module": "%(module)s", "function": "%(funcName)s", "line": %(lineno)d}'
    datefmt: '%Y-%m-%dT%H:%M:%S'

handlers:
  console:
    class: logging.StreamHandler
    formatter: json
    level: INFO
    stream: ext://sys.stdout
  
  file:
    class: logging.handlers.RotatingFileHandler
    formatter: json
    level: INFO
    filename: /var/log/app/app.log
    maxBytes: 10485760  # 10MB
    backupCount: 5

loggers:
  app:
    level: INFO
    handlers: [console, file]
    propagate: false

root:
  level: WARNING
  handlers: [console]
```

---

### 2. æŒ‡æ ‡æ”¶é›†ï¼ˆPrometheusï¼‰

#### Prometheus é…ç½®
```yaml
# observability/metrics/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'production'
    environment: 'prod'

rule_files:
  - "alerts/*.yml"

scrape_configs:
  - job_name: 'app'
    static_configs:
      - targets: ['app:8000']
        labels:
          service: 'api'
          version: 'v1.0.0'
  
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres_exporter:9187']
        labels:
          service: 'database'
  
  - job_name: 'redis'
    static_configs:
      - targets: ['redis_exporter:9121']
        labels:
          service: 'cache'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']
```

#### åº”ç”¨æŒ‡æ ‡æš´éœ²ï¼ˆPython ç¤ºä¾‹ï¼‰
```python
# modules/user/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# å®šä¹‰æŒ‡æ ‡
request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

active_connections = Gauge(
    'active_connections',
    'Active database connections'
)

# å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
start_http_server(8001)
```

---

### 3. é“¾è·¯è¿½è¸ªï¼ˆJaegerï¼‰

#### Jaeger é…ç½®
```yaml
# observability/tracing/jaeger.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-config
data:
  jaeger.yaml: |
    sampling:
      default_strategy:
        type: probabilistic
        param: 0.001  # 0.1% é‡‡æ ·ç‡
    storage:
      type: elasticsearch
      elasticsearch:
        server_urls: http://elasticsearch:9200
        index_prefix: jaeger
        username: elastic
        password: changeme
```

#### OpenTelemetry é…ç½®
```yaml
# observability/tracing/opentelemetry.yaml
exporter:
  jaeger:
    endpoint: jaeger:14250
    insecure: true

service:
  name: app-service
  version: 1.0.0

instrumentation:
  python:
    enabled: true
    packages:
      - flask
      - requests
      - sqlalchemy
```

#### Python é›†æˆç¤ºä¾‹
```python
# modules/user/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# é…ç½®è¿½è¸ªå™¨
trace.set_tracer_provider(TracerProvider())
jaeger_exporter = JaegerExporter(
    agent_host_name="jaeger",
    agent_port=6831,
)
trace.get_tracer_provider().add_span_processor(
    BatchSpanProcessor(jaeger_exporter)
)

tracer = trace.get_tracer(__name__)

# ä½¿ç”¨ç¤ºä¾‹
@tracer.start_as_current_span("create_user")
def create_user(email: str):
    with tracer.start_as_current_span("validate_email"):
        validate_email(email)
    with tracer.start_as_current_span("save_to_db"):
        save_user(email)
    return user
```

---

### 4. å‘Šè­¦é…ç½®

#### Prometheus å‘Šè­¦è§„åˆ™
```yaml
# observability/alerts/prometheus_alerts.yml
groups:
  - name: app_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "é«˜é”™è¯¯ç‡å‘Šè­¦"
          description: "é”™è¯¯ç‡è¶…è¿‡ 10% (å½“å‰å€¼: {{ $value }})"
      
      - alert: HighLatency
        expr: histogram_quantile(0.95, http_request_duration_seconds_bucket) > 2
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "é«˜å»¶è¿Ÿå‘Šè­¦"
          description: "P95 å»¶è¿Ÿè¶…è¿‡ 2 ç§’ (å½“å‰å€¼: {{ $value }}s)"
      
      - alert: LowAvailability
        expr: up{job="app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æœåŠ¡ä¸å¯ç”¨"
          description: "æœåŠ¡ {{ $labels.instance }} å·²ä¸‹çº¿è¶…è¿‡ 1 åˆ†é’Ÿ"
```

#### Alertmanager é…ç½®
```yaml
# observability/alerts/alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical'
      continue: true
    - match:
        severity: warning
      receiver: 'warning'

receivers:
  - name: 'default'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
  
  - name: 'critical'
    slack_configs:
      - channel: '#alerts-critical'
        title: 'ğŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
  
  - name: 'warning'
    slack_configs:
      - channel: '#alerts-warning'
        title: 'âš ï¸ WARNING: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

---

## éªŒè¯æ­¥éª¤

### 1. æ—¥å¿—éªŒè¯
```bash
# æ£€æŸ¥æ—¥å¿—æ˜¯å¦æ­£å¸¸æ”¶é›†
curl http://elasticsearch:9200/app-logs-*/_search?q=level:ERROR

# æ£€æŸ¥ Fluentd çŠ¶æ€
curl http://fluentd:24220/api/plugins.json
```

### 2. æŒ‡æ ‡éªŒè¯
```bash
# æ£€æŸ¥ Prometheus ç›®æ ‡
curl http://prometheus:9090/api/v1/targets

# æŸ¥è¯¢æŒ‡æ ‡
curl 'http://prometheus:9090/api/v1/query?query=up'
```

### 3. è¿½è¸ªéªŒè¯
```bash
# æ£€æŸ¥ Jaeger æœåŠ¡
curl http://jaeger:16686/api/services

# æŸ¥è¯¢è¿½è¸ª
curl 'http://jaeger:16686/api/traces?service=app-service&limit=10'
```

---

## Docker Compose é›†æˆ

```yaml
# docker-compose.observability.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./observability/metrics/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./observability/alerts:/etc/prometheus/alerts
    ports:
      - "9090:9090"
  
  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./observability/metrics/grafana_dashboards:/var/lib/grafana/dashboards
    ports:
      - "3000:3000"
  
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "6831:6831/udp"
  
  elasticsearch:
    image: elasticsearch:8.0.0
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"
  
  logstash:
    image: logstash:8.0.0
    volumes:
      - ./observability/logging/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
```

---

## ç›¸å…³æ–‡æ¡£
- è¿ç»´æ‰‹å†Œï¼š`modules/example/RUNBOOK.md`
- ç›‘æ§æŒ‡æ ‡ï¼š`docs/process/ENV_SPEC.yaml`
- æ—¥å¿—è§„èŒƒï¼š`docs/process/CONVENTIONS.md`

